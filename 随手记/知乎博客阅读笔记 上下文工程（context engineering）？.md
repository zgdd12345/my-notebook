[链接](https://zhuanlan.zhihu.com/p/1967314577529246001)

垂直领域的SFT微调根本没有必要去做，现在的大模型已经训练过足够的开源知识。检索增强生成RAG如果做得好，就足够了

RAG失败的原因：
1. 索引过多，模型接收的信息太多；
2. 索引过少，数据量太少；
3. 混合存储，非结构化的PPT、PDF、图片和结构化的markdown、word等混合数据embeding。

![[Pasted image 20251101220304.png]]

prompt engineering 已经不是核心了，context engineering 才是下一阶段的主战场。给世界上最聪明的大模型GPT5/claude 4.5喂垃圾输入，它还是会胡说八道。

跑得稳的Agent平台（比如cursor/claude code/codex），都是专注“什么该让模型看、怎么看、以什么形式看”上下了大功夫的，这一点现在应该是共识了

那实际操作中，这些高级的上下文工程到底怎么做？

## **a) [LLM](https://zhida.zhihu.com/search?content_id=265778318&content_type=Article&match_order=1&q=LLM&zhida_source=entity)的特征选择**

有个老哥换了个角度看这事儿：其实上下文工程就是传统机器学习里的特征工程，只不过换成了大模型版本。以前搞机器学习，特征工程要干这些活：抽取特征、预处理、构造新特征、筛选降维。现在大模型的各种操作，其实对应的就是这些

选择性上下文修剪，相当于特征选择（挑有用的留下）

上下文验证 ，相当于特征预处理（检查格式对不对、类型对不对、是不是过期了）

"上下文可观察性" ，还是特征预处理（追踪哪些输入让结果变好了，哪些让结果变烂了）

带元数据的嵌入增强 ， 相当于特征构造（在原有信息基础上加工出新的）

这个思路挺重要的，把看似新潮的大模型工程，对应到成熟的机器学习方法论上，很多东西就清楚了

### **b) 上下文分层：**

语义+元数据那些已经跑起来的Agent系统，大多采用双层设计

**语义层** → 就是常见的向量搜索
**元数据层** → 按文档类型、时间、访问权限或业务分类来过滤

这种混合结构能统一处理各种乱七八糟的输入（PDF、音频、日志、监控数据），确保Agent不是瞎找"看起来像"的东西，而是真正找到结构化的相关知识。本质上是在向量检索的基础上，叠加分类体系、实体关联和领域约束，让检索结果更贴近业务语义

### **c) [Text-to-SQL](https://zhida.zhihu.com/search?content_id=265778318&content_type=Article&match_order=1&q=Text-to-SQL&zhida_source=entity)能用吗？**

不能用，目前产业界没有应用

## **长短期记忆不仅仅是存储**

大模型的记忆问题大模型只有"7秒记忆"，<font color="#ffc000">模型窗口长度就是他的记忆空间，给的prompt就是他的全部记忆</font>

很多团队想做“记忆”功能，但这不是随手一加的开关，得有方案设计。要落地，需要同时考虑用户体验、隐私保护和系统架构。现在不少实现只是把对话记录简单归档，充其量是历史消息库，离真正有用的“记忆”还有差距
![[Pasted image 20251101223124.png]]

要把记忆做好，建议分层设计

- 用户层：记录个人偏好（如图表样式、写作语气）
- 团队层：沉淀常见问题、常用看板、运行手册
- 组织层：汇总知识库、规章制度和历史决策

个性化必须是透明的,用户应能清楚看到系统记录了什么，并可随时查看、修改或关闭相关记忆项

### **记忆的个性化**

记忆得让人看得见、改得了。搞 memory 系统，必须让用户知道"你记住了我什么"，而且得让用户自己能改。不然这玩意儿就不叫记忆，叫监控了。Agent 要稳定跑起来，记忆得发挥两个作用

1. 根据用户习惯做定制 —— 了解他的写作风格、常用格式、专业领域，给他量身定做
2. 主动出击，别光等着聊天 —— 根据发生的事件和数据，主动提供帮助，而不是只会被动回应

很多商业产品刚上线时都有个难题，比如 Uber 开发的对话工具，一开始根本不知道用户会问什么问题

他们根据用户过去的查询记录，建议记忆，推荐相关话题作为开场。但是个性化的帮助可能会越界侵犯隐私。比如让ChatGPT推荐一些适合全家看的电影，AI却根据家庭成员的名字给出影片的推荐，直接侵犯的用户的隐私[^1]

[^1]: 所以，用一个本地文件作为记忆，将用户输入的prompt和记忆文件作为上下文模型的输入，生成新的提示词？这样应该会更好。


### **记忆的冲突和平衡**

记忆功能能够改善用户体验并提升 Agent 的交互流畅度，但过度个性化很容易迅速触及隐私问题，如果不加以严格的范围限制，共享内存可能会突破访问控制

这里缺失了一个关键的基础要素：一种安全、可跨应用使用、由用户控制的便携式内存层。它不会被服务的提供商锁定。目前还没有人成功实现这一点。互联网公司，比如百度，360等公司产品，拼命记忆用户信息，推荐贷款，医疗等广告信息，给使用者带来很多感官不适



