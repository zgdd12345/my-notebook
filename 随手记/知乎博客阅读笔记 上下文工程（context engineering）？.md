[链接](https://zhuanlan.zhihu.com/p/1967314577529246001)

垂直领域的SFT微调根本没有必要去做，现在的大模型已经训练过足够的开源知识。检索增强生成RAG如果做得好，就足够了

RAG失败的原因：
1. 索引过多，模型接收的信息太多；
2. 索引过少，数据量太少；
3. 混合存储，非结构化的PPT、PDF、图片和结构化的markdown、word等混合数据embeding。

![[Pasted image 20251101220304.png]]

prompt engineering 已经不是核心了，context engineering 才是下一阶段的主战场。给世界上最聪明的大模型GPT5/claude 4.5喂垃圾输入，它还是会胡说八道。

跑得稳的Agent平台（比如cursor/claude code/codex），都是专注“什么该让模型看、怎么看、以什么形式看”上下了大功夫的，这一点现在应该是共识了

那实际操作中，这些高级的上下文工程到底怎么做？

## *a) [LLM](https://zhida.zhihu.com/search?content_id=265778318&content_type=Article&match_order=1&q=LLM&zhida_source=entity)的特征选择*

有个老哥换了个角度看这事儿：其实上下文工程就是传统机器学习里的特征工程，只不过换成了大模型版本。以前搞机器学习，特征工程要干这些活：抽取特征、预处理、构造新特征、筛选降维。现在大模型的各种操作，其实对应的就是这些

选择性上下文修剪，相当于特征选择（挑有用的留下）

上下文验证 ，相当于特征预处理（检查格式对不对、类型对不对、是不是过期了）

"上下文可观察性" ，还是特征预处理（追踪哪些输入让结果变好了，哪些让结果变烂了）

带元数据的嵌入增强 ， 相当于特征构造（在原有信息基础上加工出新的）

这个思路挺重要的，把看似新潮的大模型工程，对应到成熟的机器学习方法论上，很多东西就清楚了

### **b) 上下文分层：**

语义+元数据那些已经跑起来的Agent系统，大多采用双层设计

**语义层** → 就是常见的向量搜索
**元数据层** → 按文档类型、时间、访问权限或业务分类来过滤

这种混合结构能统一处理各种乱七八糟的输入（PDF、音频、日志、监控数据），确保Agent不是瞎找"看起来像"的东西，而是真正找到结构化的相关知识。本质上是在向量检索的基础上，叠加分类体系、实体关联和领域约束，让检索结果更贴近业务语义

### **c) [Text-to-SQL](https://zhida.zhihu.com/search?content_id=265778318&content_type=Article&match_order=1&q=Text-to-SQL&zhida_source=entity)能用吗？**

主持人问现场500名观众："你们有谁把text-to-SQL做到生产环境了？"结果没人举手。Text-to-SQL发展10来年，这不是因为需求不够强，而是查询理解太难了。自然语言本来就模糊，业务术语又千差万别。大模型根本不知道你们公司"收入"或"活跃用户"具体指什么，除非你做了大量的上下文工程

可靠做法是先铺好以下的基础素材，而不是直接把问题丢给模型

1、业务术语表和概念映射

2、带约束条件的查询模板

3、执行前验证层，拦住语义错误

4、反馈机制，持续优化理解能力
