[链接](https://zhuanlan.zhihu.com/p/1967314577529246001)

垂直领域的SFT微调根本没有必要去做，现在的大模型已经训练过足够的开源知识。检索增强生成RAG如果做得好，就足够了

RAG失败的原因：
1. 索引过多，模型接收的信息太多；
2. 索引过少，数据量太少；
3. 混合存储，非结构化的PPT、PDF、图片和结构化的markdown、word等混合数据embeding。

![[Pasted image 20251101220304.png]]

prompt engineering 已经不是核心了，context engineering 才是下一阶段的主战场。给世界上最聪明的大模型GPT5/claude 4.5喂垃圾输入，它还是会胡说八道。

跑得稳的Agent平台（比如cursor/claude code/codex），都是专注“什么该让模型看、怎么看、以什么形式看”上下了大功夫的，这一点现在应该是共识了

那实际操作中，这些高级的上下文工程到底怎么做？

## **a) [LLM](https://zhida.zhihu.com/search?content_id=265778318&content_type=Article&match_order=1&q=LLM&zhida_source=entity)的特征选择*

有个老哥换了个角度看这事儿：其实上下文工程就是传统机器学习里的特征工程，只不过换成了大模型版本。以前搞机器学习，特征工程要干这些活：抽取特征、预处理、构造新特征、筛选降维。现在大模型的各种操作，其实对应的就是这些

选择性上下文修剪，相当于特征选择（挑有用的留下）

上下文验证 ，相当于特征预处理（检查格式对不对、类型对不对、是不是过期了）

"上下文可观察性" ，还是特征预处理（追踪哪些输入让结果变好了，哪些让结果变烂了）

带元数据的嵌入增强 ， 相当于特征构造（在原有信息基础上加工出新的）

这个思路挺重要的，把看似新潮的大模型工程，对应到成熟的机器学习方法论上，很多东西就清楚了

### **b) 上下文分层：**

语义+元数据那些已经跑起来的Agent系统，大多采用双层设计

**语义层** → 就是常见的向量搜索
**元数据层** → 按文档类型、时间、访问权限或业务分类来过滤

这种混合结构能统一处理各种乱七八糟的输入（PDF、音频、日志、监控数据），确保Agent不是瞎找"看起来像"的东西，而是真正找到结构化的相关知识。本质上是在向量检索的基础上，叠加分类体系、实体关联和领域约束，让检索结果更贴近业务语义

### **c) [Text-to-SQL](https://zhida.zhihu.com/search?content_id=265778318&content_type=Article&match_order=1&q=Text-to-SQL&zhida_source=entity)能用吗？**

不能用，目前产业界没有应用

## **长短期记忆不仅仅是存储**

大模型的记忆问题大模型只有"7秒记忆"，模型窗口长度就是他的记忆空间，给的prompt就是他的全部记忆

很多团队想做“记忆”功能，但这不是随手一加的开关，得有方案设计。要落地，需要同时考虑用户体验、隐私保护和系统架构。现在不少实现只是把对话记录简单归档，充其量是历史消息库，离真正有用的“记忆”还有差距
