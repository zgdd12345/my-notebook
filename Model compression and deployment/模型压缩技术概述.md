Reference：<a href="https://developer.huawei.com/consumer/cn/forum/topic/0201114102935045054" title="超链接title">参考链接</a>

# 1. 模型压缩算法概述
模型压缩算法旨在将一个大模型转化为一个精简的小模型。工业界的模型压缩方法有：知识蒸馏、轻量化模型架构、剪枝、量化。

按照压缩过程对网络结构的破坏程度，《解析卷积神经网络》一书中将模型压缩技术分为“前端压缩”和“后端压缩”两部分:

<li>前端压缩，是指在不改变原网络结构的压缩技术，主要包括知识蒸馏、轻量级网络（紧凑的模型结构设计）以及滤波器（filter）层面的剪枝（结构化剪枝）等；</li>
<li>后端压缩，是指包括低秩近似、未加限制的剪枝（非结构化剪枝/稀疏）、参数量化以及二值网络等，目标在于尽可能减少模型大小，会对原始网络结构造成极大程度的改造。</li>

总结：前端压缩几乎不改变原有网络结构（仅仅只是在原模型基础上减少了网络的层数或者滤波器个数），后端压缩对网络结构有不可逆的大幅度改变，造成原有深度学习库、甚至硬件设备不兼容改变之后的网络。其维护成本很高。


工业界主流的模型压缩方法有：知识蒸馏（Knowledge Distillation，KD）轻量化模型架构（也叫紧凑的模型设计）、剪枝（Pruning）、量化（Quantization）。各个模型压缩方法总结如下：
| 模型压缩方法  | Description |涉及的网络层  |example |
| ----------- | ----------- |----------- |----------- |
| 知识蒸馏      | 迁移学习的一种，主要思想是将学习能力强的复杂教师模型中的“知识”迁移到简单的学生模型中。| 卷积和全连接层 |经典KD论文，属于蒸 "logits"方法，将Teacher Network输出的soft label作为标签来训练Student Network。必须重新训练模型。 |
| 轻量化模型架构 | 轻量级网络的核心是在尽量保持精度的前提下，从体积和速度两方面对网络进行轻量化改造。|卷积层/卷积模块|Mobilenet 提出深度可分离卷积；shufflenetv2 论文 提出的四个高效网络设计的实用指导思想；RepVGG 提出重参数化思想。都需要重新设计 backbone 和和重新训练模型。|
| 剪枝 | 将权重低于阈值的连接都从网络中删除。|卷积层和全连接层|韩松2016年Deep Compression属于开山之作，剪枝步骤：正常训练，删除网络中权重低于阈值的连接层，重新训练。需要重新训练模型。|
| 量化 |指将神经网络的浮点算法转换为定点算法 |卷积、全连接、激活、BN层等|TensoRT框架中的基于 KL 散度方法的INT8量化策略是主流技术。PTQ 训练后量化方法不需要重新训练模型。|

# 2. 知识蒸馏
一个复杂模型可由多个简单模型或者强约束条件训练得到。复杂模型特点是性能好，但其参数量大，计算效率低。小模型特点是计算效率高，但是其性能较差。知识蒸馏是让小模型去拟合大模型，从而让小模型学到与大模型相似的函数映射。使其保持其快速的计算速度前提下，同时拥有复杂模型的性能，达到模型压缩的目的。模型蒸馏的关键在于监督特征的设计，例如使用 Soft Target（软标签 KD） 所提供的类间相似性作为依据，或使用大模型的中间层特征图或 attention map 作为暗示，对小网络进行训练。整体的框架图如图下所示。<img src="img/distillation.png" alt="图片alt" title="knowledge distillation">

