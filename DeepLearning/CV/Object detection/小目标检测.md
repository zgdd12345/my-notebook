<font style="color:rgb(25, 27, 31);">对小目标检测的性能大概只有大目标的一半，因为小目标的的可视化特征过少并且一张图片中所存在的小目标个数也很少。</font>

### <font style="color:rgb(25, 27, 31);">小目标的定义</font>
小目标检测广义是指在图像中检测和识别尺寸较小、面积较小的目标物体。通常来说，小目标的定义取决于具体的应用场景，但一般可以认为小目标是指尺寸小于![image](https://cdn.nlark.com/yuque/__latex/a11ea46280669ac0bf8afdac4019d77f.svg)像素的物体，如下图 COCO 数据集的定义。当然，对于不同的任务和应用，小目标的尺寸和面积要求可能会有所不同。

![](https://cdn.nlark.com/yuque/0/2024/png/29307286/1704790358031-69e7122f-57fa-4e25-84a6-7afaa2ced6b2.png)

在 COCO 数据集中，针对三种不同大小(small，medium，large)的图片提出了测量标准，其包含大约 41% 的小目标(area<32×32), 34% 的中等目标(32×32<area<96×96), 和 24% 的大目标(area>96×96)。其中，小目标的 AP 是很难提升的！

### <font style="color:rgb(25, 27, 31);">小目标检测目前存在的困难</font>
+ **可用特征少。**小目标最根本的特征就是小，有时肉眼都无法判断。因为尺度小、分辨率低的原因，小目标的可用特征就很少了。并且它容易受到的环境的干扰，导致在检测时增加了难度。在后续的卷积过程中，就容易消失。
+ **定位精度要求高同样是偏移十个像素，对小目标的误差是远远大于大尺度、中尺度目标的。**基于anchor的检测器数目也不少，在训练时<u>对小目标进行匹配的anchor框数量</u>也会远低于大尺度目标和中尺度目标，在IOU匹配的过程中，如果<u>定位稍不准，就会认为是小目标的负样本，</u>这也进一步加具检测的难度。
+ 一般来说，每张**图像中小目标占比都很少**，大多数的目标都比较大。另外，对小目标的标注过程中，也容易<u>因为不易标注的原因以及人为疏忽而出现遗漏。</u>因为数量不多，因此<u>小目标对于误差是十分敏感</u>。
+ **样本不均衡。**大多目标检测算法都是基于anchor，在训练时，会通过设置固定的阈值来判断锚框是属于正样本还是负样本，这个阈值不一定适用于不同尺度的目标。当人为设置的anchor与小目标的gt框差异较大时，就会将大多数的anchor视为负样本，所以<u>小目标的训练正样本将远远小于大尺度、中尺度的正样本</u>，那么就会导致模型更加偏向于它们，而忽略小目标。
+ **小目标聚集。**小目标更容易发生聚集现象。<u>当小目标出现聚集时，通过多次下采样采样后，邻近的区域在特征图上就会变成一个点，导致模型无法识别。</u>另外，邻近的小目标还可能因为nms后处理而被过滤掉，从而导致漏检。还有就是如果邻近区域的小目标之间边界框距离过近，还会导致边界框很难回归
+ **外部干扰。**小目标除了分辨率低、尺度小之外，还可能融入了其他光照、噪声、遮挡的因素，这都导致它们的<u>特征质量差</u>，因此导致模型在学习上的困难。我们都知道，物体的特征对于分类和定位都尤其重要，而小目标又容易受到外部干扰，就会严重阻碍后续检测。

### <font style="color:rgb(25, 27, 31);">解决方案</font>
+ 提高图像分辨率

非常小的物体它的边界框可能只包含几个像素，提高图像的分辨率可以增加小目标的特征的丰富度。一般来说，这个可以起到立竿见影的效果。

+ 提高模型的输入大小

当有了更高分辨率的图像之后，就可以使用增大网络的输入大小，但是会导致模型的推理速度变慢。

+ 平铺图像

因为在正常图像中，小目标的个数占比还是比较少的，所以小目标的样本占比相对来说就比较低。而平铺图像就是在原本图像中增加小目标的个数，以此提高小目标的样本数，让网络在训练时，能够学习到更多的小样本目标的特征。

+ 预设anchor框

像yolov5就可以自动学习anchor框，针对这些小目标，生成更符合当前任务的anchor框。

+ 修改Anchor尺寸

首先，如何定义Anchor的尺寸大小？

生成Anchor的算法会先在主干网络的所有输出特征图上生成不同尺寸的Anchor，然后后续的操作会根据Anchor预测这些在Anchor中是否含有目标物以及真实物体和Anchor框的偏移。

因此为了提高小目标的检测效果，我们可以通过修改Anchor的尺寸来生成更加拟合小目标的Anchor。最简单的方式就是根据自己的小目标数据集生成合适的Anchor尺寸。

+ 修改Anchor数量

根据上述可知，我们能根据我们数据集中的物体大小来设计Anchor的尺寸，来在一定的程度上提高小目标物体的分类和定位精准度。

但是如果我们的在数据集中，物体的大小变化范围较大时，我们可能不能仅仅通过调节Anchor的尺寸，来提高所有物体的分类和定位准确度，所以此时我们还可以适当增加Anchor的个数，让Anchor拥有更加的尺度来实现多尺度的匹配。

+ 图像分块

和处理医疗图像的想法类似，可以在预处理时，对图像进行分块。这样可以有效地放大小目标，但是，你的模型也要适应小分辨率的输入，并且这样可以提高单个块推理的速度。但是单张图像分块后，FPS就会降低，因为会推理多个块。如果在训练阶段使用了图像分块的操作，那么推理时也要使用。

+ 数据增强

通过数据增强可以从原生的数据集基础上生成新的图像。如随机裁剪，随机旋转和mosaic。对于小目标来说特别有用，在一定程度上也可以防止模型在训练集上过拟合。

+ 重新定义类别

过滤掉无关类合理划分类别是提高数据集质量的一项重要技术。如果有一个类与另一个类明显重叠，就可以考虑从数据集中删掉这个类，那么不管是在训练阶段还是推理阶段，都要减少一个类别的开支。

+ 结合其他信息

如果是对于视频中的小目标进行检测，可以结合上下文如环境信息或者和其它容易检测的物体之间的关系来辅助小物体的检测，本质上是解决小目标本身可用的特征就很少的问题；或者结合上下帧的信息进行预测。

+ 多尺度特征融合

由于小目标的尺寸较小，其特征信息往往分布在图像的多个尺度中，因此需要在多个尺度的特征图中进行融合，以提高模型对小目标的感知能力。常见的多尺度特征融合方法包括 Feature Pyramid Networks, FPN 和 Path Aggregation Network, PAN 等。

+ 其他Tricks

比如使用Focal loss，使模型更关注困难、不平衡的样本。或者引入FPN、使用GAN生成更大分辨率的目标等等。

### 
