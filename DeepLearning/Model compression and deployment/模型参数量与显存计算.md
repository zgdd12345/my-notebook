### **1. 参数量计算**

模型的参数量（Parameters）决定了其理论复杂度，通常由各层的权重矩阵和偏置组成：
#### **(1) 全连接层 (Dense Layer)**

- 输入维度：`d_in`
- 输出维度：`d_out`
- **参数量** = `d_in * d_out + d_out`  
    （权重矩阵 `d_in×d_out` + 偏置向量 `d_out`）
#### **(2) 卷积层 (Conv2D)**
- 输入通道数：`C_in`
- 输出通道数：`C_out`
- 卷积核大小：`K×K`
- **参数量** = `C_in * C_out * （K * K） + C_out`  
    （每个卷积核的权重 `C_in×K×K`，共 `C_out` 个核 + 每个通道的偏置）

#### **(3) 循环层 (RNN/LSTM/GRU)**
- 输入维度：`d_in`
- 隐藏状态维度：`d_hidden`
- **参数量**（以LSTM为例）:  
    `4 * (d_in * d_hidden + d_hidden * d_hidden + d_hidden)`  
    （输入门、遗忘门、输出门、候选状态的权重和偏置）

#### **(4) Transformer 层**
- 隐藏维度：`d_model`
- 注意力头数：`h`
- **参数量** ≈ `12 * d_model^2 + 2 * d_model`  
    （多头注意力 + 前馈网络）

#### **(5) 总参数量**

将所有层的参数量相加，例如：

- **BERT-base**：约110M参数（12层，`d_model=768`）
    
- **GPT-3**：约175B参数

### **2. 内存/显存占用计算**
模型的参数量转化为内存/显存占用时，需考虑**数据类型**（如float32占4字节，float16占2字节）和**额外开销**（如梯度、优化器状态）。
#### **(1) 纯参数占用**
- **公式**：  
    `内存（MB） = 参数量 * 数据类型字节数 / (1024^2)`  
    例如：
    - 1亿参数的模型（float32）：  
        `100,000,000 * 4 / 1,048,576 ≈ 381.47 MB`

#### **(2) 训练时的显存占用**
训练时需要存储以下内容：
- **参数本身**：每个参数占用 `4字节`（float32）。
- **梯度***：==*每个参数的梯度同样占用 `4字节`。*==
- **优化器状态**：例如==Adam优化器需存储动量和方差，每个参数额外占用 `8字节`。==
- **中间激活值**：前向传播产生的中间结果，通常占显存大头。

**总显存公式**：

`显存 ≈ 参数内存 * (1 + 1 + 2) + 激活值内存 = 参数内存 * 4 + 激活值内存`

- **示例**：  
    一个1亿参数的模型（float32训练）：  
    `100M * 4B * 4 ≈ 1.6GB`（参数+梯度+优化器） + 激活值（假设1GB）≈ 2.6GB
    

#### **(3) 激活值内存估算**

激活值占用的显存与以下因素相关：

- **Batch Size**：更大的batch size会线性增加激活值内存。
- **网络深度**：更深的网络需要存储更多中间结果。
- **序列长度**（NLP任务）：长序列会增加注意力矩阵的内存占用（复杂度为`O(n^2)`）。
    

**经验公式**：  
激活值内存 ≈ `Batch Size * 序列长度 * 隐藏维度 * 层数 * 常数`  
例如：
- BERT-base（`seq_len=512`, `d_model=768`, `12层`）的激活值约为：  
    `Batch=32`时，约1.5-2GB。

---

### **3. 推理时的显存占用**

推理时仅需存储参数和中间激活值，且通常使用`float16`或量化技术：
- **公式**：  
    `显存 ≈ 参数内存（float16) + 激活值内存`  
    例如：
    - 1亿参数的模型（float16推理）：  
        `100M * 2B ≈ 200MB` + 激活值 ≈ 500MB

### **4. 显存优化的关键方法**

1. **混合精度训练**：  
    使用`float16`或`bfloat16`，显存占用减半。
2. **梯度检查点（Gradient Checkpointing）**：  
    用时间换空间，只存储部分激活值，其余在反向传播时重新计算。
3. **模型并行**：  
    将模型拆分到多个GPU上。
4. **优化器选择**：  
    使用显存高效的优化器（如Adafactor）。

### **5. 计算示例**
以 **BERT-base**（110M参数）为例：
- **训练显存**（float32，Batch=32）：
    - 参数：`110M * 4B ≈ 440MB`
    - 梯度：`440MB`
    - 优化器状态（Adam）：`440MB * 2 ≈ 880MB`
    - 激活值：约1.5GB
    - **总计**：`440 + 440 + 880 + 1500 ≈ 3260MB（约3.2GB）`
- **推理显存**（float16，Batch=1）：
    - 参数：`110M * 2B ≈ 220MB`
    - 激活值：约100MB
    - **总计**：`320MB`
### 6.DeepSeek
