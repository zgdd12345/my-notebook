# 大语言模型中的模型上下文协议（MCP）综述

## 1. 技术原理

**MCP 定义与设计目标：** 模型上下文协议（Model Context Protocol, MCP）是**由 Anthropic 于 2024 年提出并开源的开放标准**，旨在为大型语言模型（LLM）应用提供一个标准化接口，以连接外部数据源和工具[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE%EF%BC%88%E8%8B%B1%E8%AA%9E%EF%BC%9AModel%20Context%20Protocol%EF%BC%8C%E7%BC%A9%E5%86%99%EF%BC%9AMCP%EF%BC%89%E6%98%AFAnthropic%20%E6%89%80%E6%8E%A8%E5%8A%A8%E7%9A%84%E4%B8%80%E9%A1%B9%2063,2%20%5D%E3%80%82)。MCP 的设计目标是在保持模型强大推理能力的同时，突破传统 LLM 仅依赖训练语料的局限，使模型能够动态获取所需的上下文信息来执行更广泛、更复杂的任务[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=%5D%EF%BC%8C%E7%9B%AE%E7%9A%84%E6%98%AF%E4%B8%BA%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%8F%90%E4%BE%9B%E4%B8%80%E4%B8%AA%E6%A0%87%E5%87%86%E5%8C%96%E6%8E%A5%E5%8F%A3%EF%BC%8C%E4%BD%BF%E5%85%B6%E8%83%BD%E5%A4%9F%E8%BF%9E%E6%8E%A5%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E6%BA%90%E5%92%8C%E5%B7%A5%E5%85%B7%EF%BC%8C%E5%B9%B6%E4%B8%8E%E5%85%B6%E4%BA%A4%E4%BA%92)。**简单类比**：<u>MCP 常被比喻为 AI 应用的“USB-C 接口”，就像 USB-C 统一了设备连接标准一样</u>，MCP 统一了 AI 模型连接各种外部资源的方式[openai.github.io](https://openai.github.io/openai-agents-python/mcp/#:~:text=The%20Model%20context%20protocol%20,From%20the%20MCP%20docs)。通过这一协议，<font color="#ff0000">LLM 可以安全、规范地与外部数据源、应用和服务通信</font>[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=The%20Model%20Context%20Protocol%20,more%20accurate%2C%20useful%2C%20and%20automated)。这<span style="background:#fff88f">让 AI 助手能够跳出静态知识局限，成为动态的**代理（agent）**——既可检索最新信息，又可执行操作</span>，从而大幅提升回答的相关性、实用性和自动化程度[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=Introduced%20by%20Anthropic%20%20in,more%20accurate%2C%20useful%2C%20and%20automated)[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=applications%2C%20and%20services,more%20accurate%2C%20useful%2C%20and%20automated)。

**系统架构：** MCP 采用**三方架构**，包括 MCP 主机、MCP 客户端和 MCP 服务器[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=Model%20Context%20Protocol%20,1%29%20Tools%20for%20executing)。其中 **MCP 主机**是运行 LLM 的应用环境（例如对话系统、AI IDE 等），负责承载模型并与用户交互[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=MCP%20host)。主机内实现了 **MCP 客户端**，充当模型与外部服务的通信桥梁：它将 LLM 的请求转换为 MCP 协议格式发送给服务器，并把服务器的响应转换成模型可理解的形式注入上下文[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=MCP%20client)[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=The%20MCP%20client%2C%20located%20within,and%20uses%20available%20MCP%20servers)。**MCP 服务器**则部署在外部系统侧，用于对接具体的数据源或工具[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=MCP%20server)。服务器收到客户端请求后，与相应数据源/工具交互获取结果，并根据 MCP 规范格式化后返回给客户端[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE%E7%9A%84%E6%A0%B8%E5%BF%83%E5%9C%A8%E4%BA%8E%E5%BB%BA%E7%AB%8B%E4%B8%80%E4%B8%AA%E6%A0%87%E5%87%86%E5%8C%96%E7%9A%84%E9%80%9A%E4%BF%A1%E5%B1%82%EF%BC%8C%E4%BD%BF%E5%BE%97%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%A4%9F%E5%9C%A8%E5%A4%84%E7%90%86%E7%94%A8%E6%88%B7%E8%AF%B7%E6%B1%82%E6%88%96%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%E6%97%B6%EF%BC%8C%E5%A6%82%E6%9E%9C%E9%9C%80%E8%A6%81%E8%AE%BF%E9%97%AE%E5%A4%96%E9%83%A8%E4%BF%A1%E6%81%AF%E6%88%96%E5%8A%9F%E8%83%BD%EF%BC%8C%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87MCP%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%90%91MCP%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%91%20%E9%80%81%E8%AF%B7%E6%B1%82%E3%80%82MCP%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%99%E8%B4%9F%E8%B4%A3%E4%B8%8E%E7%9B%B8%E5%BA%94%E7%9A%84%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E6%BA%90%E6%88%96%E5%B7%A5%E5%85%B7%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92%EF%BC%8C%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E5%B9%B6%E6%8C%89%E7%85%A7MCP%E5%8D%8F%E8%AE%AE%E8%A7%84%E8%8C%83%E8%BF%9B%E8%A1%8C%E6%A0%BC%E5%BC%8F%E5%8C%96%EF%BC%8C%E6%9C%80%E5%90%8E%E5%B0%86%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%90%8E%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BF%94%E5%9B%9E%E7%BB%99%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E3%80%82%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A5%E6%94%B6%E5%88%B0%E4%B8%8A)。这种标准化的通信层确保了模型在需要外部信息或功能时，可以通过客户端发送请求，服务器执行操作并返回结果，从而实现上下文信息的双向交换[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=ImageMCP%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%85%B3%E7%B3%BB)。值得注意的是，MCP 建立的是**状态化连接**，即在一次会话中模型和服务器可以多轮交互，维护上下文连续性，并在通信开始时协商双方支持的功能和协议版本[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=MCP%E7%9A%84%E6%A0%B8%E5%BF%83%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E5%9F%BA%E4%BA%8EJSON,2)[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=MCP%E7%9A%84%E6%A0%B8%E5%BF%83%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E5%9F%BA%E4%BA%8EJSON,2)。这种能力协商机制保证了在多模态或多组件系统中，不同 MCP 实现之间能够协调一致地管理上下文信息和功能调用[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=MCP%E7%9A%84%E6%A0%B8%E5%BF%83%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E5%9F%BA%E4%BA%8EJSON,2)。

**运行机制：** 在 MCP 框架下，当 LLM 处理用户请求时，如果识别到需要外部数据或操作，就会触发 MCP 工作流程[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=At%20its%20core%2C%20the%20Model,email%20it%20to%20my%20manager)。例如，用户询问:“查找最新销售报告并发送邮件给经理。” 对于这样的复合指令，LLM 将明白自身无法直接访问数据库或发送邮件，于是通过 MCP：_(1) 工具发现：_ 模型经由 MCP 客户端检索可用的工具（由各 MCP 服务器注册提供），找到“数据库查询”和“邮件发送”两个工具[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=Here%20is%20a%20simplified%20look,how%20MCP%20would%20handle%20this)；_(2) 工具调用：_ 模型依据协议生成结构化的调用请求，首先调用数据库查询工具并附上报告名称，客户端将该请求发送到相应 MCP 服务器[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=1,the%20company%27s%20database%2C%20and%20retrieves)；_(3) 外部执行与数据返回：_ MCP 服务器将请求翻译为安全的数据库查询，检索销售报告数据，格式化后返回给模型[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=client%20then%20sends%20this%20request,I%20have%20found)；_(4) 连续操作：_ 模型拿到报告数据后，再调用邮件发送工具，提供经理邮箱和报告内容，服务器执行发送并确认完成[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=translates%20it%20into%20a%20secure,emailed%20it%20to%20your%20manager)；_(5) 最终应答：_ 模型综合结果，向用户确认：“我已找到最新销售报告并通过邮件发送给您的经理。”[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=2,MCP%20server%20confirms%20the%20action)。整个过程中，模型通过 MCP **逐步发现并编排多个工具**来满足用户请求，展示了 MCP 在多组件系统中协调上下文和操作的强大能力。

**通信协议与功能：** MCP 通信底层采用 JSON-RPC 2.0 协议，以 JSON 结构封装请求和响应[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=MCP%E7%9A%84%E6%A0%B8%E5%BF%83%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E5%9F%BA%E4%BA%8EJSON,2)。这种轻量级远程过程调用格式使消息标准化且易于解析，同时支持**多种传输方式**[openai.github.io](https://openai.github.io/openai-agents-python/mcp/#:~:text=Currently%2C%20the%20MCP%20spec%20defines,the%20transport%20mechanism%20they%20use)：对于本地资源通常使用标准输入/输出（STDIO）子进程通信，实现快速同步交互；对于远程服务则支持基于 HTTP 的服务端事件流（SSE）或可流式的 HTTP 传输，以实现高效实时的数据传输[openai.github.io](https://openai.github.io/openai-agents-python/mcp/#:~:text=Currently%2C%20the%20MCP%20spec%20defines,the%20transport%20mechanism%20they%20use)。在 MCP 体系中，服务器可提供三类核心功能：[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=MCP%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%AF%E4%BB%A5%E5%90%91%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%8F%90%E4%BE%9B%E4%BB%A5%E4%B8%8B%E5%8A%9F%E8%83%BD%EF%BC%9A)一是**资源（Resources）**，即结构化或非结构化的数据上下文，例如文件内容、数据库记录等；二是**提示（Prompts）**，即模板化的消息或工作流程，用于帮助用户或模型更好地完成任务（比如预定义的指令模版）；三是**工具（Tools）**，即模型可调用的函数或操作接口，如执行代码、查询API、发送指令等。这三类功能涵盖了从纯数据检索到实际动作执行的上下文增强方式。反过来，客户端（模型一侧）也向服务器提供**采样（Sampling）**能力，即允许服务器在需要时发起由模型代理执行的行为，甚至进行递归的 LLM 交互[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=MCP%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8F%AF%E4%BB%A5%E5%90%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8F%90%E4%BE%9B%E4%BB%A5%E4%B8%8B%E5%8A%9F%E8%83%BD%EF%BC%9A)（例如服务器可以请求模型对某段数据进行总结，再将结果返回）。此外，MCP 协议还定义了**附加实用工具**以完善通信可靠性，包括配置协商、进度跟踪、操作取消、错误报告和日志记录等机制[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=MCP%20%E8%BF%98%E5%AE%9A%E4%B9%89%E4%BA%86%E4%BB%A5%E4%B8%8B%E9%99%84%E5%8A%A0%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7%EF%BC%8C%E4%BB%A5%E5%A2%9E%E5%BC%BA%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%8A%9F%E8%83%BD%EF%BC%9A)。这些设计使 MCP 在多模态、多组件场景下具备良好的扩展性和健壮性：例如，可通过协议协商扩展支持图像、音频等数据格式（有研究提出在 MCP 基础上通过多部分消息实现多模态传输[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=each%20addressing%20interoperability%20in%20distinct,Based%20on%20the)），并利用日志和错误处理保障复杂交互的语义一致性和可追溯性。

## 发展过程

**提出背景：** 随着大语言模型在 2023 年取得突破，如何让模型掌握最新信息、调用外部工具成为亟待解决的问题。OpenAI 于 2023 年推出了函数调用接口，使 GPT-4 等模型能够以结构化方式调用外部 API[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=In%20recent%20years%2C%20the%20vision,LLM%20app%20stores%20such%20as)；随后 ChatGPT 插件体系上线，开发者可为 ChatGPT 定义工具接口(OpenAPI)供模型使用[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=with%20external%20systems,including%20Anthropic%2C%20Google%2C%20and%20Meta)。同期，许多第三方框架兴起，如 LangChain 和 LlamaIndex，为不同 LLM 提供了封装工具调用的方案[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=developers%20to%20build%20callable%20tools,including%20Anthropic%2C%20Google%2C%20and%20Meta)。Google、Meta 等也开发了各自的插件或工具接入机制，推动了 AI 工具生态的发展[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=Frameworks%20like%20LangChain%C2%A0,in%20dynamically%20discovering%20and%20orchestrating)。然而，这些尝试彼此割裂：每种模型或平台都有不同的接口定义、鉴权方式和调用逻辑[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=provided%20standardized%20tool%20interfaces%2C%20making,dynamically%20discovering%20and%20orchestrating%20tools)。开发者不得不针对每个数据源定制集成，缺乏统一标准，导致多平台支持成本高、难以扩展。更重要的是，现有方案大多依赖预设的工具清单和固定流程，限制了 AI **自主**地动态发现和编排新工具的能力[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=external%20services,dynamically%20discovering%20and%20orchestrating%20tools)。

**关键里程碑：** 针对上述痛点，Anthropic 于 2024 年11月正式提出并开源了模型上下文协议（MCP）[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=In%20late%202024%2C%20Anthropic%20introduced,AI%20applications%20and%20improves%20their)。MCP 的设计深受软件领域语言服务器协议（LSP）的启发[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=In%20late%202024%2C%20Anthropic%20introduced,AI%20applications%20and%20improves%20their)——后者成功地标准化了编辑器与编程语言工具的通信。同样地，MCP 希望成为 AI 助手连接外部世界的通用桥梁，让模型可自主地发现、选择并协调外部服务，而非依赖硬编码的接口映射[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=In%20late%202024%2C%20Anthropic%20introduced,AI%20applications%20and%20improves%20their)。Anthropic 发布 MCP 规范和 SDK 后，Claude 大模型及其桌面应用率先支持作为 MCP 客户端，提供了内置的本地 MCP 服务器连接能力[anthropic.com](https://www.anthropic.com/news/model-context-protocol#:~:text=,source%20repository%20of%20MCP%20servers)。他们还开源了多个典型 MCP 服务器实现（连接 Google Drive、Slack、GitHub、数据库等），供开发者即装即用[anthropic.com](https://www.anthropic.com/news/model-context-protocol#:~:text=,source%20repository%20of%20MCP%20servers)。早期采用者如 Block (Square 公司) 和 Apollo 等将 MCP 集成到各自系统中验证效果，而 Zed、Replit、Codeium、Sourcegraph 等开发者工具公司则与 Anthropic 合作，将 MCP 引入 IDE 等场景，为代码助手获取上下文提供支持[anthropic.com](https://www.anthropic.com/news/model-context-protocol#:~:text=Early%20adopters%20like%20Block%20and,functional%20code%20with%20fewer%20attempts)。这些里程碑标志着 MCP 从概念走向实践：开发者可以不再为每个数据源维护单独的插件，而是**“一处对接，处处通用”**——针对 MCP 标准开发一次，模型即可访问多种外部资源[anthropic.com](https://www.anthropic.com/news/model-context-protocol#:~:text=MCP%20addresses%20this%20challenge,to%20the%20data%20they%20need)[anthropic.com](https://www.anthropic.com/news/model-context-protocol#:~:text=Instead%20of%20maintaining%20separate%20connectors,with%20a%20more%20sustainable%20architecture)。

**生态演进：** MCP 发布后最初反响平平，但在 2025 年初开始迅速升温[huggingface.co](https://huggingface.co/blog/Kseniase/mcp#:~:text=To%20simplify%20that%2C%20Anthropic%20came,Why)[huggingface.co](https://huggingface.co/blog/Kseniase/mcp#:~:text=MCP%20was%20first%20open,reasons%20for%20this%20recent%20buzz)。随着越来越多开发者意识到 MCP 是打通 AI 与业务系统数据孤岛的关键一环[huggingface.co](https://huggingface.co/blog/Kseniase/mcp#:~:text=,AI%20models%2C%20each%20specialized%20for)，社区贡献进入爆发期：不到三个月时间里，社区构建了超过 **1000** 个 MCP 服务器连接器，覆盖从网络搜索、数据库查询到邮件发送等各类工具[huggingface.co](https://huggingface.co/blog/Kseniase/mcp#:~:text=Apollo%2C%20Zed%2C%20Replit%2C%20Codeium%2C%20and,by%20a%20major%20AI%20player)。MCP 由此形成**网络效应**：可用工具越丰富，采用该标准的价值就越高，反过来又吸引更多人加入开发[huggingface.co](https://huggingface.co/blog/Kseniase/mcp#:~:text=Apollo%2C%20Zed%2C%20Replit%2C%20Codeium%2C%20and,by%20a%20major%20AI%20player)。到2025年中，MCP 俨然成为行业默认标准：每周 SDK 下载量已超过 **800 万次**，表明其在开发者中的受欢迎程度[arxiv.org](https://arxiv.org/abs/2506.13538#:~:text=distinct%20tool%20interfaces,assess%20their%20health%2C%20security%2C%20and)。众多 AI 领先机构和开源社区也开始围绕 MCP 集结[huggingface.co](https://huggingface.co/blog/Kseniase/mcp#:~:text=The%20reaction%20was%20sort%20of,Why)[huggingface.co](https://huggingface.co/blog/Kseniase/mcp#:~:text=framework%2C%20MCP%20is%20open%20and,just%20release%20MCP%20and%20walk)。例如，OpenAI 在其新推出的 **Agents SDK** 中加入了对 MCP 的支持，使 GPT-4 等模型能够使用任何符合 MCP 标准的工具和上下文源[openai.github.io](https://openai.github.io/openai-agents-python/mcp/#:~:text=Model%20context%20protocol%20)[openai.github.io](https://openai.github.io/openai-agents-python/mcp/#:~:text=The%20Agents%20SDK%20has%20support,and%20prompts%20to%20your%20Agents)。Google 则通过云平台详细解读并推广 MCP 的用法，帮助企业将自有数据接入 AI[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=The%20Model%20Context%20Protocol%20,more%20accurate%2C%20useful%2C%20and%20automated)。此外，诸如 Cursor IDE（智能编程助手）利用 MCP 来检索代码库和开发文档[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=3,MCP%20Server%20Hosting%20and%20Scalability)；Cloudflare 提供远程 MCP 服务器的托管和负载扩展方案，方便大规模部署[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=1,MCP%20Server%20Hosting%20and%20Scalability)。可以说，2024 年底至 2025 年，MCP 从一个新提议迅速发展为大模型应用的**基石组件**[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=To%20address%20these%20issues%2C%20Anthropic,their%20parameters%2C%20MCP%20separates%20retrieval)。它统一了AI与外部系统交互的语言，大幅降低了接入新工具的门槛，被视为标准化 AI 系统连接外界的有力竞争者，有望像 USB、HTTP 等协议那样普及[huggingface.co](https://huggingface.co/blog/Kseniase/mcp#:~:text=standard.%20,just%20release%20MCP%20and%20walk)。

## 最新研究成果（2024年至今）

**功能优化与评估：** MCP 的出现引发了学术界和工业界对 “模型+工具” 体系的新一波研究热潮。为了量化 MCP 是否真正提升了模型性能，研究者提出了专门的评测框架。例如，Song 等人（2025）构建了 **MCPGauge**，从**主动性**、**遵从性**、**有效性**和**开销**四个维度系统评估 LLM 使用 MCP 工具的行为[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=We%20propose%20MCPGauge%2C%20the%20first,reasoning%2C%20and%20code%20generation%20tasks)。他们设计了包含160个提示、25个任务数据集的大规模基准，对6种主流商业大模型在单轮和多轮对话下的工具使用进行了约2万次调用测试[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=interactions%20along%20four%20key%20dimensions%3A,These)[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=)。结果揭示了若干出人意料的现象：[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=revealed%20four%20surprising%20and%20insightful,%284%29%20MCP)(1) 大多数模型在**首次对话轮次**几乎不会主动调用工具，只有经过一两轮“热身”后才逐渐学会善用外部工具；(2) 模型对显式指令的**遵从性**有限，只有当要求使用工具的指令被逐步嵌入对话时，模型才会较好地执行，单轮明示往往不足以驱动工具使用；(3) **引入外部上下文未必提升准确率**——自动工具调用反而平均使核心任务准确率下降约9.5%，表明检索到的额外信息有时与模型内部推理存在不一致，产生了干扰[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=indicating%20a%20limited%20ability%20to,design%2C%20particularly%20for%20developing%20more)；(4) 工具整合带来**显著的计算开销**，模型输入长度大幅增加（提示和结果会占用额外 token），在某些任务上得不偿失[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=9.5,augmented%20LLM%20agents)。这些研究在顶会论文中首次系统揭示了当前 MCP-Augmented 模型的瓶颈，也为后续优化指明了方向：例如需要提高模型自主识别何时需要工具的能力，改进提示策略以减少上下文冲突，并控制调用带来的额外开销[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=find%20that%20proactive%20tool%20use,token%20overhead)[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=misalignment%20between%20retrieved%20context%20and,token%20overhead)。

**可扩展性与安全性：** 另一系列研究关注 MCP 生态系统本身的效率和安全问题。随着社区已开源上千种 MCP 服务器，有工作对其可维护性和漏洞进行了大规模扫描分析。Hasan 等人（2025）采集了 1899 个开源 MCP 服务器项目，利用静态分析和 MCP 专用扫描器评估其健康状况，结果发现虽然大部分服务器代码质量较高，但仍存在8类独特漏洞（其中仅3类与传统软件漏洞重叠），约7.2%的服务器含通用安全漏洞，5.5%存在“MCP 特有的**工具投毒**”风险[arxiv.org](https://arxiv.org/abs/2506.13538#:~:text=MCP%27s%20AI,specific%20tool%20poisoning.%20Regarding)。此外，14.4%的项目代码中检测到模式化缺陷或异味[arxiv.org](https://arxiv.org/abs/2506.13538#:~:text=maintainability,source%20software%20projects.%20These%20findings)。这一研究敲响警钟：尽管 MCP 便利了工具接入，但**AI 驱动的非确定性控制流**引入了新的安全挑战，亟需发展针对 MCP 的漏洞检测和防护技术[arxiv.org](https://arxiv.org/abs/2506.13538#:~:text=Protocol%20,assess%20their%20health%2C%20security%2C%20and)[arxiv.org](https://arxiv.org/abs/2506.13538#:~:text=traditional%20software%20vulnerabilities.%20Additionally%2C%207.2,specific%20vulnerability%20detection%20techniques%20while)。另一方面，Hou 等人（2025）的综述论文对 MCP 架构及整个生态进行了全面审视，分析了 MCP 服务器从创建、运行到更新各阶段可能面临的安全与隐私威胁，并提出相应的缓解策略[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=The%20Model%20Context%20Protocol%20,the%20current%20MCP%20landscape%2C%20including)[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=three%20key%20phases%3A%20creation%2C%20operation%2C,AI%20landscape%20continues%20to%20evolve)。他们讨论了如**命名冲突**、**安装包冒充**、**代码注入/后门**、**沙箱逃逸**等具体攻击面，以及在工具发布、版本升级过程中权限滥用和配置漂移等问题[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=Assistants%20%203,2%20Slash%20Command%20Overlap)[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=1,Update%20Privilege%20Persistence)。为此，作者建议在 MCP 基础设施中引入更加严格的安全审核和沙箱隔离机制，并为企业级应用制定安全框架[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=As%20MCP%20adoption%20has%20expanded%2C,of%20deploying%20MCP%20in%20production)。例如，Radosevich 和 Halloran（2025）对 MCP 进行安全审计，演示了攻击者可利用 MCP 环境的弱点来诱导模型执行恶意操作，即使模型本身经过齐心训练也可能被利用[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=As%20MCP%20adoption%20has%20expanded%2C,and%20mitigation%20strategies%20for%20MCP)。Narajala 和 Habler（2025）则提出了面向企业的 MCP 安全框架和缓解策略，探索在生产环境部署 MCP 时保持高安全性的方案[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=frameworks%20like%20ours%20for%20understanding,exploitation%20methods%20in%20MCP%20systems)。可以预见，随着 MCP 成为 AI 系统常态，此领域的安全研究将持续深化。

**模型协同与协议拓展：** MCP 聚焦于“一主机-多工具”的模型单体增强，而近期业界和学界开始探讨**多智能体协作**所需的新协议。2025 年出现了若干与 MCP 平行的协议标准：例如 **Agent-to-Agent 协议 (A2A)**，旨在支持 LLM 之间对等通信，允许一个代理将子任务委派给另一代理完成，再通过协议交换结果[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=Agent,scale%20task%20orchestration%C2%A0%5B9)[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=communication%20protocols%3A%20Model%20Context%20Protocol,LD%20graphs.%20The)；**Agent Communication Protocol (ACP)** 则侧重本地多代理系统的消息传递，采用 REST 风格异步通信并支持多段消息体，以便在代理之间传输文本、图像等多模态内容[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=each%20addressing%20interoperability%20in%20distinct,Based%20on%20the)[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=Agent%20Communication%20Protocol%20,agent%20systems%C2%A0%5B10)。此外还有面向开放代理网络的 **Agent Network Protocol (ANP)**，引入去中心化标识（DID）和知识图谱，实现开放环境下的代理发现和安全协作[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=exchange.%20ACP%20introduces%20REST,multimodal%20messaging%2C%20A2A%20for%20collaborative)[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=with%20multi,agent%20systems%C2%A0%5B10)。顶级会议的一些前沿报告和综述已开始比较这些协议在交互模式、发现机制、通信模型和安全框架方面的差异[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=communication%20protocols%3A%20Model%20Context%20Protocol,LD%20graphs.%20The)[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=)。总体趋势是：**标准化**正从 MCP 的工具调用层，逐步延伸到代理之间更丰富的语义通信层[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=to,foundation%20for%20designing%20secure%2C%20interoperable)。例如，有研究提出一个分阶段采用路线图：首先以 MCP 实现工具接入标准化，然后引入 ACP 支持多模态消息，进而通过 A2A 实现跨智能体的任务协作，最终扩展到 ANP 以构建开放的代理市场[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=9,41)[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=each%20addressing%20interoperability%20in%20distinct,Based%20on%20the)。这一系列探索表明，MCP 已成为“大模型+多组件”系统演进的基石，而围绕其的改进和新协议创新，正推动 AI 系统朝更加模块化、互操作的方向发展。

## 未来研究方向

展望未来，MCP 在上下文整合、通信协议、语义一致性、多代理协作等方面仍有诸多挑战和潜在研究路线：

- **上下文整合：** 如何让模型更智能地检索和整合外部知识，将是持续研究重点。MCP 已提供获取实时数据的通道，但仍需优化模型的**检索决策**机制——让模型知道何时需要求助工具，以及如何提出有效的查询。从**检索增强生成**（RAG）技术来看，检索到的文本往往用于提高答案的事实性，而 MCP 则侧重执行操作和双向交互[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=Both%20Model%20Context%20Protocol%20,system%20for%20interaction%20and%20action)[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=Standardize%20two,perform%20actions%20alongside%20information%20retrieval)。未来可能融合 RAG 与 MCP 的优点：一方面利用知识库提高回答准确性，另一方面通过标准协议执行操作。为避免模型获取到不相关或冲突的信息，研究者或将开发更智能的上下文筛选与融合算法，以及让模型在生成答案时显式标记引用外部信息来源，以提升回答的可信度和可追溯性。
    
- **通信协议扩展：** 随着需求增长，MCP 本身的协议可能需要扩展以支持更复杂的交互和数据类型。例如，在**多模态**方面，未来的 AI 助手应能请求图像分析、音频识别等服务并获取非文本结果。这可能需要在 MCP 框架中引入**多部分消息**或附件机制，以传输图像、视频等富媒体数据（类似 ACP 提出的方案[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=each%20addressing%20interoperability%20in%20distinct,Based%20on%20the)）。同时，在**实时交互**方面，协议需要支持更高效的流式通信和并发，确保模型在长对话或长工具链调用时不受限于单一请求-响应。进一步的改进还包括**标准语义格式**（例如通过 JSON 模式严格定义工具输入输出的语义，以减少模型和工具之间的误解）以及**错误自动恢复**（当工具调用失败或出错时，协议可以引导模型采取纠正措施）。这些扩展要求既要保持 MCP 的通用性，又要兼顾不同模态、不同场景的特殊需求，是协议演进的一大方向。
    
- **语义一致性：** 当模型将外部上下文纳入推理，如何保证其内部知识与外部信息的一致性是一个棘手问题。正如研究所示，模型有时**无法有效利用检索信息，甚至因为信息不一致而性能下降**[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=indicating%20a%20limited%20ability%20to,design%2C%20particularly%20for%20developing%20more)。未来需要在模型推理过程中引入**语义校对**和**一致性检测**机制。例如，模型获取外部知识后，可以有一个验证步骤：将新信息与模型已有的知识图谱或事实存储比对，评估冲突之处并据此调整回答或请求更多澄清。另一思路是在模型输出中引入不确定性标记，当外部信息与内部推理不符时提醒用户或开发者介入。为了实现这些，可能需要改进模型的架构（如在注意力机制中增加对来源的区分权重）或训练方式（如通过监督学习教模型正确引用和整合外部信息）。语义一致性也涉及**上下文记忆**：当多轮对话调用多次工具时，模型需记住先前获得的外部信息并避免自相矛盾。这可能需要在 MCP 客户端维护一个共享的**上下文缓存/黑板**，供模型在会话中查阅，保证多工具、多轮次交互后的回答在语义上前后一致。
    
- **多代理协作：** 在单模型调用工具之外，更远的未来是多个智能体协同工作。为此，需要建立**代理间通信协议**和共享上下文的机制。当前的 MCP 可以看作执行层面的协议标准，而多代理协作则需要在决策层引入新的约定。例如，一个代理可以通过 **Agent-to-Agent (A2A)** 协议向另一代理发送任务请求，并附带必要的上下文[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=Agent,scale%20task%20orchestration%C2%A0%5B9)。每个代理可能有不同的专长（如文字生成、代码编写、数据分析等），它们协作时需要一种**共享语义基础**来理解彼此的意图、能力声明和上下文标识。这方面的初步研究（如 ACP、A2A 等）已经提出了**消息类型、意图、能力卡片**等概念，用于描述代理能做什么、收到消息该如何处理等[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=each%20addressing%20interoperability%20in%20distinct,Based%20on%20the)[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=)。未来研究或将探索将 MCP 与这些代理协议结合起来，形成分层次的通信框架：底层通过 MCP 接入外部工具，上层通过 A2A/ACP 等实现代理之间的分工与对话。例如，在企业级工作流中，一个总控代理可以根据任务需求动态调用多个专业子代理，各子代理再各自通过 MCP访问相应工具，最后汇总结果完成复杂任务。这种多代理体系对**上下文共享**和**语义一致**要求更高，因为所有代理需要对整体任务有共同理解。可能的研究方向包括：设计**集中式的记忆或黑板系统**，记录所有代理的动作和得到的中间结果；引入**协议中继或网关**（类似 Lasso MCP Gateway[research.aimultiple.com](https://research.aimultiple.com/mcp-gateway#:~:text=AIMultiple%20research,agents%20and%20multiple%20MCP%20servers)），在多个 MCP 服务器和代理之间协调通信；以及制定**代理社会规则**，防止代理间出现沟通不良或冲突。多代理协作有望极大提升 AI 系统的复杂任务处理能力，但也对上下文协议提出了新的挑战，是未来值得深入探索的领域。
    

综上，模型上下文协议（MCP）作为连接大模型与外部世界的关键创新，已在短时间内展现出巨大潜力。从技术原理上看，它为上下文信息的获取与使用提供了统一机制，在多模态、多组件系统中实现了高效的上下文管理与调用。其发展历程体现了开放标准的力量：迅速凝聚了业界共识，成为大模型系统的重要基石。最新的研究进展既验证了 MCP 的价值，也揭示了当前模型在工具使用上的不足、协议生态中的安全隐患等问题。展望未来，通过在上下文整合、通信协议、语义一致性和多代理协作等方向的持续研究与改进，我们有望构建更加**智能**、**可靠**、**协同**的下一代大模型应用系统，让 AI 更顺畅地融入人类知识体系和数字生态[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=applications%2C%20and%20services,more%20accurate%2C%20useful%2C%20and%20automated)[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=To%20address%20these%20issues%2C%20Anthropic,their%20parameters%2C%20MCP%20separates%20retrieval)。

**参考文献：**

1. Anthropic. _Introducing the Model Context Protocol_. 2024年11月25日[anthropic.com](https://www.anthropic.com/news/model-context-protocol#:~:text=Today%2C%20we%27re%20open,produce%20better%2C%20more%20relevant%20responses)[anthropic.com](https://www.anthropic.com/news/model-context-protocol#:~:text=MCP%20addresses%20this%20challenge,to%20the%20data%20they%20need).
    
2. Anthropic. _Model Context Protocol 官方网站: Introduction 页面_[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE%EF%BC%88%E8%8B%B1%E8%AA%9E%EF%BC%9AModel%20Context%20Protocol%EF%BC%8C%E7%BC%A9%E5%86%99%EF%BC%9AMCP%EF%BC%89%E6%98%AFAnthropic%20%E6%89%80%E6%8E%A8%E5%8A%A8%E7%9A%84%E4%B8%80%E9%A1%B9%2063,2%20%5D%E3%80%82)[zh.wikipedia.org](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE#:~:text=MCP%E7%9A%84%E6%A0%B8%E5%BF%83%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E5%9F%BA%E4%BA%8EJSON,2).
    
3. Google Cloud. _What is the MCP and how does it work?_ 2025年[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=The%20Model%20Context%20Protocol%20,more%20accurate%2C%20useful%2C%20and%20automated)[cloud.google.com](https://cloud.google.com/discover/what-is-model-context-protocol#:~:text=Here%20is%20a%20simplified%20look,how%20MCP%20would%20handle%20this).
    
4. OpenAI. _OpenAI Agents SDK – Model context protocol (MCP) 文档_[openai.github.io](https://openai.github.io/openai-agents-python/mcp/#:~:text=The%20Model%20context%20protocol%20,From%20the%20MCP%20docs)[openai.github.io](https://openai.github.io/openai-agents-python/mcp/#:~:text=Currently%2C%20the%20MCP%20spec%20defines,the%20transport%20mechanism%20they%20use).
    
5. Ksenia S. _What Is MCP, and Why Is Everyone Suddenly Talking About It?_ Hugging Face社区文章, 2025年3月17日[huggingface.co](https://huggingface.co/blog/Kseniase/mcp#:~:text=To%20simplify%20that%2C%20Anthropic%20came,Why)[huggingface.co](https://huggingface.co/blog/Kseniase/mcp#:~:text=Apollo%2C%20Zed%2C%20Replit%2C%20Codeium%2C%20and,by%20a%20major%20AI%20player).
    
6. Wei Song 等. _Help or Hurdle? Rethinking MCP-Augmented LLMs_. 2025年8月, arXiv:2508.12566[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=revealed%20four%20surprising%20and%20insightful,trivial)[arxiv.org](https://arxiv.org/html/2508.12566v1#:~:text=indicating%20a%20limited%20ability%20to,design%2C%20particularly%20for%20developing%20more).
    
7. Mohammed M. Hasan 等. _MCP at First Glance: Security and Maintainability of MCP Servers_. 2025年6月, arXiv:2506.13538[arxiv.org](https://arxiv.org/abs/2506.13538#:~:text=distinct%20tool%20interfaces,assess%20their%20health%2C%20security%2C%20and)[arxiv.org](https://arxiv.org/abs/2506.13538#:~:text=MCP%27s%20AI,specific%20tool%20poisoning.%20Regarding).
    
8. Xinyi Hou 等. _Model Context Protocol: Landscape, Security Threats, and Future Research Directions_. 2025年3月, arXiv:2503.23278[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=The%20Model%20Context%20Protocol%20,the%20current%20MCP%20landscape%2C%20including)[arxiv.org](https://arxiv.org/html/2503.23278v2#:~:text=Assistants%20%203,2%20Slash%20Command%20Overlap).
    
9. Abul Ehtesham 等. _A Survey of Agent Interoperability Protocols: MCP, ACP, A2A, ANP_. 2025年5月, arXiv:2505.02279[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=communication%20protocols%3A%20Model%20Context%20Protocol,LD%20graphs.%20The)[arxiv.org](https://arxiv.org/html/2505.02279v1#:~:text=each%20addressing%20interoperability%20in%20distinct,Based%20on%20the).